# -*- coding: utf-8 -*-
"""PhishingDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mb5-potN10NIio3Q64M4UwH18UXd61eE
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data0 = pd.read_csv('Ph1.csv')
data0.head()

data0.shape

data0.columns

data0.info()

data0.describe()

data0['Label'].value_counts()

data0.hist(bins = 50,figsize = (15,15))
plt.show()

plt.figure(figsize=(15,13))
sns.heatmap(data0.corr(),annot=True)
plt.show()

data0.describe()

data = data0.drop(['Domain'], axis = 1).copy()

data.isnull().sum()

data = data.sample(frac=1).reset_index(drop=True)
data.head()

data0['URL_Depth'].unique()

data0['Domain_Age'].unique()

data0['Web_Traffic'].value_counts()

data0.isnull().sum()

sns.countplot(x='URL_Depth',data=data0,hue='Label')

sns.scatterplot(x='URL_Depth',y='Label',data=data0,hue='TinyURL')

sns.countplot(x='URL_Length',data=data,palette='Set2')
plt.show()

y = data['Label']
X = data.drop('Label',axis=1)
X.shape, y.shape

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.2, random_state = 12)
X_train.shape, X_test.shape

from sklearn.metrics import accuracy_score

ML_Model = []
acc_train = []
acc_test = []

#function to call for storing the results
def storeResults(model, a,b):
  ML_Model.append(model)
  acc_train.append(round(a, 3))
  acc_test.append(round(b, 3))

from sklearn.tree import DecisionTreeClassifier

# instantiate the model
mod = DecisionTreeClassifier(max_depth = 5)
# fit the model
mod=mod.fit(X_train, y_train)

y_test_tree = mod.predict(X_test)
y_train_tree = mod.predict(X_train)

acc_train_tree = accuracy_score(y_train,y_train_tree)
acc_test_tree = accuracy_score(y_test,y_test_tree)

print("Decision Tree: Accuracy on training Data: {:.3f}".format(acc_train_tree))
print("Decision Tree: Accuracy on test Data: {:.3f}".format(acc_test_tree))

from sklearn import tree
plt.figure(figsize=(10,5))
tree.plot_tree(mod,fontsize=5)
plt.show()

plt.figure(figsize=(9,7))
n_features = X_train.shape[1]
plt.barh(range(n_features), mod.feature_importances_, align='center')
plt.yticks(np.arange(n_features), X_train.columns)
plt.xlabel("Feature importance")
plt.ylabel("Feature")
plt.show()

sns.countplot(x='URL_Length',hue='URL_Depth',data=data0)

storeResults('Decision Tree', acc_train_tree, acc_test_tree)

from sklearn.ensemble import RandomForestClassifier

# instantiate the model
forest = RandomForestClassifier(max_depth=5)

# fit the model
forest.fit(X_train, y_train)

y_test_forest = forest.predict(X_test)
y_train_forest = forest.predict(X_train)

acc_train_forest = accuracy_score(y_train,y_train_forest)
acc_test_forest = accuracy_score(y_test,y_test_forest)

print("Random forest: Accuracy on training Data: {:.3f}".format(acc_train_forest))
print("Random forest: Accuracy on test Data: {:.3f}".format(acc_test_forest))

from sklearn.metrics import classification_report
print(classification_report(y_test, y_test_forest))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
rf = RandomForestClassifier()
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)

grid_search.fit(X_train, y_train)
print("Best parameters:", grid_search.best_params_)
best_rf_model = grid_search.best_estimator_

forest=RandomForestClassifier(max_depth= None, min_samples_leaf= 1, min_samples_split= 5, n_estimators= 100)
forest.fit(X_train,y_train)

acc1_train=accuracy_score(forest.predict(X_train),y_train)
print(f"Training: {accuracy_score(forest.predict(X_train),y_train)}")

y_pred=forest.predict(X_test)
acc2=accuracy_score(forest.predict(X_train),y_train)
print(f"Accuracy:{accuracy_score(y_test,y_pred)}")

plt.figure(figsize=(9,7))
n_features = X_train.shape[1]
plt.barh(range(n_features), forest.feature_importances_, align='center')
plt.yticks(np.arange(n_features), X_train.columns)
plt.xlabel("Feature importance")
plt.ylabel("Feature")
plt.show()

storeResults('Random Forest', acc_train_forest, acc_test_forest)



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization ,Activation
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint

X_train.shape

model = Sequential()
model.add(Dense(32, activation = 'relu', input_shape = (16, )))
model.add(Dense(16, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.summary()

opt = keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer= opt ,loss='binary_crossentropy',metrics=['acc'])

class myCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('val_loss')<0.1):
            print("\nReached 0.1 val_loss so cancelling training!")
            self.model.stop_training = True

callback = myCallback()

history = model.fit(X_train, y_train, epochs=100,batch_size=256, callbacks=[callback],validation_data=(X_test,y_test),verbose=1)

print(history.history.keys())

# summarize history for accuracy
plt.figure(figsize=(20,8))
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.figure(figsize=(20,8))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

loss, val_acc = model.evaluate(X_test,y_test,verbose=1)
loss,acc=model.evaluate(X_train,y_train)
print('Test loss: {}'.format(loss))
print('Train Accuracy:{}'.format(acc))
print('Test Accuracy: {}'.format(val_acc))



pred_test = model.predict(X_test)
for i in range (len(pred_test)):
    if (pred_test[i] < 0.5):
        pred_test[i] = 0
    else:
        pred_test[i] = 1
pred_test = pred_test.astype(int)
def view_result(array):
    array = np.array(array)
    for i in range(len(array)):
        if array[i] == 0:
            print("Non Mallicious")
        else:
            print("Mallicious")

print("PREDICTED : ")
view_result(pred_test[:10])
print("\n")
print("ACTUAL : ")
view_result(y_test[:10])

storeResults('Multilayer Perceptrons', acc, val_acc )

from xgboost import XGBClassifier

xgb = XGBClassifier(learning_rate=0.4,max_depth=7)

xgb.fit(X_train, y_train)

y_test_xgb = xgb.predict(X_test)
y_train_xgb = xgb.predict(X_train)

acc_train_xgb = accuracy_score(y_train,y_train_xgb)
acc_test_xgb = accuracy_score(y_test,y_test_xgb)

print("XGBoost: Accuracy on training Data: {:.3f}".format(acc_train_xgb))
print("XGBoost : Accuracy on test Data: {:.3f}".format(acc_test_xgb))

from sklearn.metrics import classification_report
report = classification_report(y_test, y_test_xgb, output_dict=True)
df_report = pd.DataFrame(report).transpose()
plt.figure(figsize=(10, 6))
sns.heatmap(df_report.iloc[:-1, :].T, annot=True, fmt=".2f")
plt.title('Classification Report')
plt.xlabel('Metrics')
plt.ylabel('Classes')
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_test_xgb)
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

storeResults('XGBoost', acc_train_xgb, acc_test_xgb)

from sklearn.svm import SVC
# instantiate the model
svm = SVC(kernel='linear', C=1.0, random_state=12)
#fit the model
svm.fit(X_train, y_train)

y_test_svm = svm.predict(X_test)
y_train_svm = svm.predict(X_train)

acc_train_svm = accuracy_score(y_train,y_train_svm)
acc_test_svm = accuracy_score(y_test,y_test_svm)
print("SVM: Accuracy on training Data: {:.3f}".format(acc_train_svm))
print("SVM : Accuracy on test Data: {:.3f}".format(acc_test_svm))

storeResults('SVM', acc_train_svm, acc_test_svm)

results = pd.DataFrame({ 'ML Model': ML_Model,
    'Train Accuracy': acc_train,
    'Test Accuracy': acc_test})
results

results.sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending=False)

plt.plot(results['Train Accuracy'],data=results)
plt.plot(results['Test Accuracy'],data=results)
plt.xticks(ticks=range(len(results['ML Model'])), labels=results['ML Model'], rotation=45)
plt.xlabel('Models')

sns.histplot(x=results['Train Accuracy'],y=results['ML Model'],data=results)
sns.histplot(x=results['Test Accuracy'],y=results['ML Model'],data=results,color='red')
plt.show()

import pickle
pickle.dump(xgb, open("XGBoostClassifier.pickle.dat", "wb"))

loaded_model = pickle.load(open("XGBoostClassifier.pickle.dat", "rb"))
loaded_model

xgb.predict(np.array([[0,0,24,3,0,0,0,0,0,1,0,0,0,0,0,0]]))

xgb.predict(np.array([[0,0,1,4,0,0,0,0,0,1,0,1,0,0,1,0]]))

xgb.predict(np.array([[0,0,16,3,0,1,1,0,0,None,None,0,0,0,0,0]]))

xgb.predict(np.array([[0,0,16,3,0,1,1,0,0,1,1,0,0,0,0,0]]))

xgb.predict(np.array([[0,0,24,3,0,1,0,0,0,0,0,1,0,0,0,0]]))